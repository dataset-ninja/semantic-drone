The primary goal of the **Semantic Drone Dataset** is to enhance the safety of autonomous drone flight and landing procedures through improved semantic comprehension of urban environments. This dataset comprises imagery captured from a bird's-eye (nadir) perspective, showcasing over 20 houses, taken at altitudes ranging from 5 to 30 meters above the ground. The images are acquired using a high-resolution camera with a size of 6000x4000 pixels (24 megapixels). The training set includes 400 publicly accessible images, while the test set consists of 200 private images. Additionally, the dataset provides bounding box annotations for person detection within both the training and test sets.
